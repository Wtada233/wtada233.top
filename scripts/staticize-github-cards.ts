import crypto from "node:crypto";
import fs from "node:fs";
import path from "node:path";
import type { Root } from "mdast";
import remarkDirective from "remark-directive";
import remarkParse from "remark-parse";
import { unified } from "unified";
import { visit } from "unist-util-visit";
import { getFilesRecursive } from "./utils";

/**
 * ğŸ“¦ æºç çº§ GitHub å¡ç‰‡é™æ€åŒ–å·¥å…· (API ä¼˜å…ˆ + è‡ªåŠ¨é‡è¯•ç‰ˆ)
 *
 * ç­–ç•¥ï¼š
 * 1. æ€»æ˜¯å°è¯•è¯·æ±‚ GitHub API è·å–æœ€æ–°æ•°æ®ã€‚
 * 2. å¦‚æœè¯·æ±‚æˆåŠŸï¼Œæ›´æ–° Markdown æºç ã€‚
 * 3. å¦‚æœè¯·æ±‚å¤±è´¥ï¼ˆé‡è¯• 5 æ¬¡åï¼‰ï¼Œä¿ç•™æºç ä¸­åŸæœ‰çš„é™æ€æ•°æ®ã€‚
 */

const CONTENT_DIR = "src/content";
const PUBLIC_DIR = "public";
const AVATAR_PATH = path.join("assets", "external");
const SAVE_DIR = path.join(PUBLIC_DIR, AVATAR_PATH);

if (!fs.existsSync(SAVE_DIR)) {
	fs.mkdirSync(SAVE_DIR, { recursive: true });
}

async function wait(ms: number) {
	return new Promise((resolve) => setTimeout(resolve, ms));
}

async function downloadAvatar(url: string): Promise<string | null> {
	if (!url) return null;
	// å³ä½¿æœ¬åœ°æœ‰æ–‡ä»¶ï¼Œå¶å°”æ›´æ–°ä¸€ä¸‹ä¹Ÿæ˜¯å¥½çš„ï¼Œä½†ä¸ºäº†æ„å»ºé€Ÿåº¦ï¼Œè¿™é‡Œå¯ä»¥å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	// å¦‚æœéœ€è¦å¼ºåˆ·æ–°å¤´åƒï¼Œå¯ä»¥ç§»é™¤è¿™ä¸ªæ£€æŸ¥
	// è¿™é‡Œä¿æŒç®€å•çš„å“ˆå¸Œæ£€æŸ¥é€»è¾‘

	// æˆ‘ä»¬å…ˆè®¡ç®—é¢„æœŸæ–‡ä»¶åï¼ˆåŸºäº URLï¼‰ï¼Œå¦‚æœ URL æ²¡å˜ï¼Œå†…å®¹å¤§æ¦‚ç‡æ²¡å˜
	// ä½†ä¸ºäº†ç¡®ä¿ä¸‡æ— ä¸€å¤±ï¼Œæˆ‘ä»¬è¿˜æ˜¯åœ¨ API è¯·æ±‚æˆåŠŸåå†ä¸‹è½½

	try {
		const response = await fetchWithRetry(url);
		if (!response) return null;

		const buffer = await response.arrayBuffer();
		if (buffer.byteLength < 50) {
			console.warn(`  [WARN] Downloaded avatar too small (${buffer.byteLength} bytes): ${url}`);
			return null;
		}
		const hash = crypto.createHash("md5").update(Buffer.from(buffer)).digest("hex");
		const filename = `avatar-${hash}.png`;
		const savePath = path.join(SAVE_DIR, filename);
		const publicUrl = `/${AVATAR_PATH}/${filename}`;

		if (!fs.existsSync(savePath)) {
			fs.writeFileSync(savePath, Buffer.from(buffer));
		}
		return publicUrl;
	} catch (e) {
		console.warn(`  [WARN] Failed to download avatar ${url}: ${String(e)}`);
		return null;
	}
}

async function fetchWithRetry(url: string, retries = 5, headers: HeadersInit = {}): Promise<Response | null> {
	for (let i = 0; i < retries; i++) {
		try {
			const response = await fetch(url, { headers });
			if (response.ok) return response;
			if (response.status === 404) return null; // 404 ä¸é‡è¯•
			if (response.status === 403) {
				// Rate limit hit
				console.warn(`  [RATE LIMIT] Hit limit for ${url}, waiting...`);
				await wait(1000 * (i + 1));
			}
			throw new Error(`HTTP ${response.status}`);
		} catch (e) {
			if (i === retries - 1) throw e;
			const delay = 1000 * 2 ** i; // æŒ‡æ•°é€€é¿
			console.log(`  [RETRY] ${url} failed, retrying in ${delay}ms...`);
			await wait(delay);
		}
	}
	return null;
}

async function fetchRepoData(repo: string) {
	console.log(`  >> Fetching GitHub data: ${repo}`);
	const headers: HeadersInit = {
		"User-Agent": "Astro-Blog-Staticizer",
	};
	if (process.env.GITHUB_TOKEN) {
		headers.Authorization = `token ${process.env.GITHUB_TOKEN}`;
	}

	try {
		const response = await fetchWithRetry(`https://api.github.com/repos/${repo}`, 5, headers);

		if (!response) {
			console.warn(`  [WARN] Failed to fetch data for ${repo} (After retries)`);
			return null;
		}

		const data = await response.json();
		const localAvatar = await downloadAvatar(data.owner?.avatar_url);

		// æ›´å¥å£®çš„æè¿°æ¸…ç†ï¼šç§»é™¤ Emoji æ ‡è®°ï¼Œæ›¿æ¢æ‰€æœ‰åŒå¼•å·ï¼Œå¹¶ç§»é™¤å¯èƒ½å¹²æ‰°è§£æçš„æ§åˆ¶å­—ç¬¦
		const cleanDescription = (data.description || "No description")
			.replace(/:[a-zA-Z0-9_]+:/g, "")
			.replaceAll('"', "'")
			.replace(/[\n\r\t]/g, " ")
			.trim();

		return {
			description: cleanDescription,
			language: data.language || "Unknown",
			stars: Intl.NumberFormat("en-us", { notation: "compact", maximumFractionDigits: 1 }).format(data.stargazers_count).replaceAll("\u202f", ""),
			forks: Intl.NumberFormat("en-us", { notation: "compact", maximumFractionDigits: 1 }).format(data.forks).replaceAll("\u202f", ""),
			license: data.license?.spdx_id || data.license?.name || "None",
			avatar: localAvatar || data.owner?.avatar_url || "",
		};
	} catch (e) {
		console.warn(`  [ERROR] Network error for ${repo}: ${String(e)}`);
		return null;
	}
}

function cleanupOrphanedFiles() {
	console.log("\x1b[33m%s\x1b[0m", ">> Cleaning up orphaned avatars...");
	const allFiles = getFilesRecursive(CONTENT_DIR, [".md", ".mdx"]);
	const existingAssets = fs.readdirSync(SAVE_DIR);
	const usedAssets = new Set<string>();

	for (const file of allFiles) {
		const content = fs.readFileSync(file, "utf-8");
		for (const asset of existingAssets) {
			if (content.includes(asset)) {
				usedAssets.add(asset);
			}
		}
	}

	let deletedCount = 0;
	for (const asset of existingAssets) {
		if (!usedAssets.has(asset)) {
			fs.unlinkSync(path.join(SAVE_DIR, asset));
			console.log(`  [CLEANUP] Deleted orphaned avatar: ${asset}`);
			deletedCount++;
		}
	}
	console.log(`>> Cleanup completed. (${deletedCount} assets removed)`);
}

interface DirectiveNode {
	type: string;
	name: string;
	attributes?: {
		repo?: string;
		description?: string;
		stars?: string;
		avatar?: string;
	};
	position?: {
		start: { offset: number };
		end: { offset: number };
	};
}

async function main() {
	console.log("\x1b[36m%s\x1b[0m", ">> Starting Source-level GitHub Staticization (API Priority)...");
	const files = getFilesRecursive(CONTENT_DIR, [".md", ".mdx"]);
	const processor = unified().use(remarkParse).use(remarkDirective);
	const repoMap = new Map<
		string,
		{
			description: string;
			language: string;
			stars: string;
			forks: string;
			license: string;
			avatar: string;
		}
	>();

	for (const file of files) {
		const rawContent = fs.readFileSync(file, "utf-8");
		const tree = processor.parse(rawContent) as Root;
		const changes: { start: number; end: number; repo: string }[] = [];

		visit(tree, "leafDirective", (node: unknown) => {
			const dNode = node as DirectiveNode;
			if (dNode.name === "github") {
				const repo = dNode.attributes?.repo;
				if (!repo) return;

				// æ— è®ºæ˜¯å¦å·²é™æ€åŒ–ï¼Œéƒ½å°†å…¶åŠ å…¥å¾…å¤„ç†é˜Ÿåˆ—ï¼Œä»¥å°è¯•æ›´æ–°æ•°æ®
				changes.push({
					start: dNode.position?.start.offset || 0,
					end: dNode.position?.end.offset || 0,
					repo: repo,
				});
			}
		});

		if (changes.length === 0) continue;

		let content = rawContent;
		// å€’åºæ›¿æ¢
		for (let i = changes.length - 1; i >= 0; i--) {
			const change = changes[i];
			if (!repoMap.has(change.repo)) {
				const data = await fetchRepoData(change.repo);
				if (data) {
					repoMap.set(change.repo, data);
				} else {
					console.warn(`\x1b[33m[WARN]\x1b[0m Skipping GitHub staticization for ${change.repo} after failed retries (Offline or Network Error).`);
				}
			}

			const data = repoMap.get(change.repo);
			if (data) {
				// ä»…å½“æˆåŠŸè·å–åˆ°æ–°æ•°æ®æ—¶ï¼Œæ‰æ›´æ–°æºç 
				const staticDirective = `::github{repo="${change.repo}" description="${data.description}" stars="${data.stars}" forks="${data.forks}" license="${data.license}" language="${data.language}" avatar="${data.avatar}"}`;
				content = content.slice(0, change.start) + staticDirective + content.slice(change.end);
			}
		}

		if (content !== rawContent) {
			fs.writeFileSync(file, content);
			console.log(`âœ… Updated source: ${file}`);
		}
	}
	console.log("\x1b[32m%s\x1b[0m", ">> GitHub Source Staticization completed.");
	cleanupOrphanedFiles();
}

main().catch(console.error);
